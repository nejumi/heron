defaults:
  - base_config
  - _self_

wandb:
 log: true
 entity: "vision-language-leaderboard"
 project: "heron-leaderboard"
 run_name: "cyberagent/llava-calm2-siglip"
 launch: false

testmode: false
torch_dtype: "bf16"
api: false
model_artifact: null
processor_artifact: null
tokenizer_artifact: null

model:
 _target_: transformers.LlavaForConditionalGeneration.from_pretrained
 pretrained_model_name_or_path: "cyberagent/llava-calm2-siglip"
 torch_dtype: "bfloat16"

processor:
 _target_: transformers.AutoProcessor.from_pretrained
 pretrained_model_name_or_path: "cyberagent/llava-calm2-siglip"

tokenizer: null
generation:
 args:
   max_length: 256
   do_sample: true
   temperature: 0.2
   no_repeat_ngram_size: 2